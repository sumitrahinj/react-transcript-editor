{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./packages/stt-adapters/bbc-kaldi/group-words-by-speakers.js","webpack:///./packages/stt-adapters/bbc-kaldi/index.js","webpack:///./packages/stt-adapters/autoEdit2/index.js","webpack:///./packages/stt-adapters/speechmatics/index.js","webpack:///./packages/stt-adapters/amazon-transcribe/group-words-by-speakers.js","webpack:///./packages/stt-adapters/amazon-transcribe/index.js","webpack:///./packages/stt-adapters/ibm/index.js","webpack:///./packages/stt-adapters/digital-paper-edit/index.js","webpack:///./packages/stt-adapters/create-entity-map/index.js","webpack:///./packages/stt-adapters/google-stt/index.js","webpack:///./packages/stt-adapters/index.js","webpack:///./packages/stt-adapters/digital-paper-edit/group-words-by-speakers.js","webpack:///./packages/stt-adapters/generate-entities-ranges/index.js"],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","groupWordsInParagraphsBySpeakers","words","segments","wordsWithSpeakers","currentSpeaker","speaker","results","paragraph","text","forEach","word","push","punct","trim","groupWordsBySpeaker","tmpWordsWithSpeakers","tmpSpeakerSegment","tmpSegment","find","seg","segEnd","start","duration","end","gender","findSegmentForWord","addSpeakerToEachWord","bbcKaldiToDraft","bbcKaldiJson","tmpWords","speakerSegmentation","retval","segmentation","test","join","groupWordsInParagraphs","speakerLabel","draftJsContentBlockParagraph","type","data","entityRanges","generateEntitiesRanges","autoEdit2ToDraft","autoEdit2Json","autoEditText","autoEditparagraph","autoEditLine","line","tmpWord","startTime","endTime","getSpeaker","speakers","speakerIdx","segmentStart","parseFloat","speechmaticsToDraft","speechmaticsJson","curatedWords","length","toString","maxParagraphWords","newSpeaker","oldSpeaker","sentenceEnd","map","element","index","time","confidence","toLowerCase","replace","paragraphStart","findSpeakerForWord","start_time","end_time","firstMatchingSegment","speaker_label","speakerLabels","groupedWords","groupWordsBySpeakerLabel","w","assign","addSpeakerLabelToWords","getBestAlternativeForWord","alternatives","reduce","prev","current","normalizeWord","currentWord","bestAlternative","content","mapPunctuationItemsToWords","itemsToRemove","punctuation","previousWord","punctuationContent","appendPunctuationToPreviousWord","filter","item","includes","amazonTranscribeToDraft","amazonTranscribeJson","items","speaker_labels","wordsWithRemappedPunctuation","speakerGroup","groupSpeakerWordsInParagraphs","normalizedWord","ibmToDraft","ibmJson","ibmWords","ibmSpeakers","ibmResults","normalisedResults","normalisedWords","result","timestamps","ibmWord","ibmNormalisedWordsWithSpeakers","draftJsParagraphsResults","ibmParagraph","lines","speakerSegments","segStart","from","to","findSpeakerSegmentForWord","digitalPaperEditToDraft","digitalPaperEditTranscriptJson","paragraphs","generateDraftJsContentBlock","flatten","list","a","b","concat","Array","isArray","createEntityMap","blocks","block","flatEntityRanges","entityMap","mutability","computeTimeInSeconds","startSecond","nanoSecond","seconds","sentences","sentence","getBestAlternativeSentence","transcript","nanos","gcpSttToDraft","gcpSttJson","sttJsonAdapter","transcriptData","sttJsonType","console","error","currentSegment","currentSegmentIndex","previousSegmentIndex","indexOf","addWordsToSpeakersParagraphs","wordAttributeName","position","offset","risk_level","risklevel","Math","random","substring"],"mappings":"2BACE,IAAIA,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUC,QAGnC,IAAIC,EAASJ,EAAiBE,GAAY,CACzCG,EAAGH,EACHI,GAAG,EACHH,QAAS,IAUV,OANAI,EAAQL,GAAUM,KAAKJ,EAAOD,QAASC,EAAQA,EAAOD,QAASF,GAG/DG,EAAOE,GAAI,EAGJF,EAAOD,QA0Df,OArDAF,EAAoBQ,EAAIF,EAGxBN,EAAoBS,EAAIV,EAGxBC,EAAoBU,EAAI,SAASR,EAASS,EAAMC,GAC3CZ,EAAoBa,EAAEX,EAASS,IAClCG,OAAOC,eAAeb,EAASS,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEZ,EAAoBkB,EAAI,SAAShB,GACX,oBAAXiB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAeb,EAASiB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAeb,EAAS,aAAc,CAAEmB,OAAO,KAQvDrB,EAAoBsB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQrB,EAAoBqB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFA1B,EAAoBkB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOrB,EAAoBU,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRzB,EAAoB6B,EAAI,SAAS1B,GAChC,IAAIS,EAAST,GAAUA,EAAOqB,WAC7B,WAAwB,OAAOrB,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAH,EAAoBU,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRZ,EAAoBa,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG/B,EAAoBkC,EAAI,GAIjBlC,EAAoBA,EAAoBmC,EAAI,I,oGCmCtCC,MA/Gf,SAA0CC,EAAOC,GAM/C,OA2BF,SAA6BC,GAAoB,IAC3CC,EAAiBD,EAAkB,GAAGE,QACpCC,EAAU,GACZC,EAAY,CAAEN,MAAO,GAAIO,KAAM,GAAIH,QAAS,IA0BhD,OAzBAF,EAAkBM,SAAQ,SAACC,GAErBN,IAAmBM,EAAKL,SAC1BE,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,MAAQE,EAAKE,MAAQ,IAC/BL,EAAUF,QAAUD,IAKpBA,EAAiBM,EAAKL,QAEtBE,EAAUC,KAAOD,EAAUC,KAAKK,OAEhCP,EAAQK,KAAKJ,IAEbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,GAAIH,QAAS,UAElCJ,MAAMU,KAAKD,GACrBH,EAAUC,MAAQE,EAAKE,MAAQ,QAInCN,EAAQK,KAAKJ,GAEND,EA1DQQ,CAWjB,SAA8Bb,EAAOC,GACnC,IAAMa,EAAuB,GAQ7B,OAPAd,EAAMQ,SAAQ,SAACC,GACb,IAyFuBL,EAzFjBW,EA4DV,SAA4BN,EAAMR,GAEhC,IAAMe,EAAaf,EAASgB,MAAK,SAACC,GAChC,IAAMC,EAASD,EAAIE,MAAQF,EAAIG,SAE/B,OAASZ,EAAKW,OAASF,EAAIE,OAAWX,EAAKa,KAAOH,KALV,YAQtC,IAAAH,EAGK,CACL,QAAS,UAGTZ,QAAS,CAAE,MAAO,MAAOmB,OAAQ,MAI5BP,EA/EmBQ,CAAmBf,EAAMR,GAEnDQ,EAAKL,SAuFkBA,EAvFUW,EAAkBX,SAwFtCmB,OAAS,IAAMnB,EAAQ,OAvFpCU,EAAqBJ,KAAKD,MAGrBK,EAtBmBW,CAAqBzB,EAAOC,EAASA,YCkFlDyB,EAtDS,SAAAC,GAAiB,IAEnCC,EADEvB,EAAU,GAEZwB,EAAsB,KAgD1B,YA3CI,IAAAF,EAAaG,QAMfF,EAAWD,EAAa3B,WACpB,IAAA2B,EAAaI,eACfF,EAAsBF,EAAaI,gBAPrCH,EAAWD,EAAaG,OAAO9B,WAC3B,IAAA2B,EAAaG,OAAOC,eACtBF,EAAsBF,EAAaG,OAAOC,gBASlB,OAAxBF,EA1CyB,SAAA7B,GAAU,IACjCK,EAAU,GACZC,EAAY,CAAEN,MAAO,GAAIO,KAAM,IAiBnC,OAfAP,EAAMQ,SAAQ,SAAAC,GAER,QAAQuB,KAAKvB,EAAKE,QACpBL,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,KAAKG,KAAKD,EAAKE,OACzBL,EAAUC,KAAOD,EAAUC,KAAK0B,KAAK,KACrC5B,EAAQK,KAAKJ,GAEbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,MAE/BD,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,KAAKG,KAAKD,EAAKE,WAItBN,EAwBe6B,CAAuBN,GAEvB7B,EAAiC6B,EAAUC,IAG/CrB,SAAQ,SAACF,EAAWvC,GAGpC,QAAI,IAAAuC,EAAUN,MAAM,GAAkB,CACpC,IAAImC,EAAY,cAAWpE,GACC,OAAxB8D,IACFM,EAAe7B,EAAUF,SAG3B,IAAMgC,EAA+B,CACnC7B,KAAMD,EAAUC,KAChB8B,KAAM,YACNC,KAAM,CACJlC,QAAS+B,EACTnC,MAAOM,EAAUN,MACjBoB,MAAOd,EAAUN,MAAM,GAAGoB,OAI5BmB,aAAcC,YAAuBlC,EAAUN,MAAO,UAExDK,EAAQK,KAAK0B,OAIV/B,GCfMoC,EA1BU,SAACC,GAAmB,IACrCrC,EAAU,GAsBhB,OAxD6B,SAACsC,GAAkB,IAC1CtC,EAAU,GACZC,EAAY,CAAEN,MAAO,GAAIO,KAAM,IA4BnC,OA1BAoC,EAAanC,SAAQ,SAACoC,GACpBA,EAAkBtC,UAAUE,SAAQ,SAACqC,GACnCA,EAAaC,KAAKtC,SAAQ,SAACC,GAIzB,IAAMsC,EAAU,CACdxC,KAAME,EAAKF,KACXa,MAAOX,EAAKuC,UACZ1B,IAAKb,EAAKwC,SAGR,QAAQjB,KAAKvB,EAAKF,OACpBD,EAAUN,MAAMU,KAAKqC,GACrBzC,EAAUC,KAAKG,KAAKD,EAAKF,MACzBF,EAAQK,KAAKJ,GAEbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,MAE/BD,EAAUN,MAAMU,KAAKqC,GACrBzC,EAAUC,KAAKG,KAAKD,EAAKF,gBAM1BF,EAMmB6B,CADTQ,EAAcnC,MAGbC,SAAQ,SAACF,EAAWvC,GACpC,IAAMqE,EAA+B,CACnC7B,KAAMD,EAAUC,KAAK0B,KAAK,KAC1BI,KAAM,YACNC,KAAM,CACJlC,QAAQ,OAAD,OAAUrC,GACjBiC,MAAOM,EAAUN,MACjBoB,MAAOd,EAAUN,MAAM,GAAGoB,OAI5BmB,aAAcC,YAAuBlC,EAAUN,MAAO,SAGxDK,EAAQK,KAAK0B,MAIR/B,GCxDH6C,EAAa,SAAC9B,EAAO+B,GACzB,IAAK,IAAIC,KAAcD,EAAU,CAAC,IAC1B/C,EAAU+C,EAASC,GACnBC,EAAeC,WAAWlC,GAChC,GAAIiC,GAAgBjD,EAAQgB,MAAQiC,EAAejD,EAAQkB,IACzD,OAAOlB,EAAQ9B,KAInB,MAAO,OAyGMiF,EAhDa,SAACC,GAAsB,IAfxBxD,EACnByD,EAeApD,EAAU,GA4ChB,OA5DyBL,EAmBIwD,EAAiBxD,MAlBxCyD,EAAe,GACrBzD,EAAMQ,SAAQ,SAACC,GACT,QAAQuB,KAAKvB,EAAKnC,OACpBmF,EAAaA,EAAaC,OAAS,GAAGpF,KAAOmF,EAAaA,EAAaC,OAAS,GAAGpF,KAAOmC,EAAKnC,KAC/FmF,EAAaA,EAAaC,OAAS,GAAGrC,UAAYiC,WAAWG,EAAaA,EAAaC,OAAS,GAAGrC,UAAYiC,WAAW7C,EAAKY,WAAWsC,YAE1IF,EAAa/C,KAAKD,MAxCO,SAACT,EAAOmD,EAAUS,GAAuB,IAIlEC,EAHExD,EAAU,GACZC,EAAY,CAAEN,MAAO,GAAIO,KAAM,GAAIH,QAAS,IAC5C0D,EAAaZ,EAAWlD,EAAM,GAAGoB,MAAO+B,GAExCY,GAAW,EAoBf,OAlBA/D,EAAMQ,SAAQ,SAACC,KACboD,EAAaX,EAAWzC,EAAKW,MAAO+B,MAEjBW,GAAexD,EAAUN,MAAM0D,OAASE,GAAqBG,KAC9EzD,EAAUF,QAAU0D,EACpBzD,EAAQK,KAAKJ,GACbwD,EAAaD,EAEbvD,EAAY,CAAEN,MAAO,GAAIO,KAAM,KAEjCD,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,KAAKG,KAAKD,EAAKE,OACzBoD,IAAc,QAAQ/B,KAAKvB,EAAKE,UAGlCL,EAAUF,QAAU0D,EACpBzD,EAAQK,KAAKJ,GAEND,EAiDmB6B,CA7BnBuB,EAQaO,KAAI,SAACC,EAASC,GAChC,MAAQ,CACN9C,MAAO6C,EAAQE,KACf7C,KAAMgC,WAAWW,EAAQE,MAAQb,WAAWW,EAAQ5C,WAAWsC,WAC/DS,WAAYH,EAAQG,WACpB3D,KAAMwD,EAAQ3F,KAAK+F,cAAcC,QAAQ,SAAU,IACnD3D,MAAOsD,EAAQ3F,KACf4F,MAAOA,MAKGV,EAAiBL,SACLa,KAAI,SAACC,GAC7B,MAAQ,CACN7C,MAAOkC,WAAWW,EAAQE,MAC1B7C,IAAMgC,WAAWW,EAAQE,MAAQb,WAAWW,EAAQ5C,UACpD/C,KAAM2F,EAAQ3F,SAIsD,KAEtDkC,SAAQ,SAACF,GAAe,IAClCiE,EAAiBjE,EAAUN,MAAM,GAAGoB,MACpCgB,EAA+B,CACnC7B,KAAMD,EAAUC,KAAK0B,KAAK,KAC1BI,KAAM,YACNC,KAAM,CACJlC,QAASE,EAAUF,QACnBJ,MAAOM,EAAUN,MACjBoB,MAAOmD,GAIThC,aAAcC,YAAuBlC,EAAUN,MAAO,UAExDK,EAAQK,KAAK0B,MAGR/B,GC1GImE,EAAqB,SAAC/D,EAAMR,GAAc,IAC/C+C,EAAYM,WAAW7C,EAAKgE,YAC5BxB,EAAUK,WAAW7C,EAAKiE,UAC1BC,EAAuB1E,EAASgB,MAAK,SAACC,GAC1C,OAAO8B,GAAaM,WAAWpC,EAAIuD,aAAexB,GAAWK,WAAWpC,EAAIwD,aAJ1B,YAMhD,IAAAC,EACK,MAEAA,EAAqBC,cAAcN,QAAQ,OAAQ,KAQjDzD,EAAsB,SAACb,EAAO6E,GAGzC,OAtCsC,SAAC7E,GAAW,IAC5C8E,EAAe,GACjB3E,EAAiB,GAarB,OAZAH,EAAMQ,SAAQ,SAACC,GACTA,EAAKmE,gBAAkBzE,EACzB2E,EAAaA,EAAapB,OAAS,GAAG1D,MAAMU,KAAKD,IAEjDN,EAAiBM,EAAKmE,cAEtBE,EAAapE,KAAK,CAChBN,QAASK,EAAKmE,cACd5E,MAAO,CAAES,SAIRqE,EAuBAC,CAPsB,SAAC/E,EAAOC,GACrC,OAAOD,EAAMgE,KAAI,SAAAgB,GAAC,OAAIvG,OAAOwG,OAAOD,EAAG,CAAE,cAAiBR,EAAmBQ,EAAG/E,QAItDiF,CAAuBlF,EAAO6E,EAAc5E,Y,orBC5BjE,IAUMkF,EAA4B,SAAA1E,GACvC,MAAI,cAAcuB,KAAKvB,EAAK4B,MACnB5D,OAAOwG,OAAOxE,EAAK2E,aAAa,GAAI,CAAEhB,WAAY,IAEzB3D,EAAK2E,aAAaC,QAAO,SACzDC,EACAC,GAEA,OAAOjC,WAAWgC,EAAKlB,YAAcd,WAAWiC,EAAQnB,YACpDkB,EACAC,MAUFC,EAAgB,SAAAC,GACpB,IAAMC,EAAkBP,EAA0BM,GAElD,MAAO,CACLrE,MAAOkC,WAAWmC,EAAYhB,YAC9BnD,IAAKgC,WAAWmC,EAAYf,UAC5BnE,KAAMmF,EAAgBC,QACtBvB,WAAYd,WAAWoC,EAAgBtB,cAgB9BwB,EAA6B,SAAA5F,GAAU,IAC5C6F,EAAgB,GAatB,OAZmB7F,EAAMgE,KAAI,SAACvD,EAAMyD,GAAU,MAE1B,gBAAdzD,EAAK4B,MACPwD,EAAcnF,KAAKwD,EAAQ,GAjBc,SAAC4B,EAAaC,GAC3D,IAAMC,EAAqBF,EAAYV,aAAa,GAAGO,QAEvD,OAAO,EAAP,KACKI,GADL,IAEEX,aAAcW,EAAaX,aAAapB,KAAI,SAAAgB,GAAC,cACxCA,GADwC,IAE3CW,QAASX,EAAEW,SAhDgBlF,EAgDYuF,EA/CpCvF,EAAK6D,QAAQ,MAAO,OADI,IAAA7D,OA6DpBwF,CAAgCxF,EAFxBT,EAAMkE,EAAQ,KAItBzD,KAIOyF,QAAO,SAACC,EAAMjC,GAC9B,OAAQ2B,EAAcO,SAASlC,OA6EpBmC,EAhCiB,SAAAC,GAAyB,IACjDjG,EAAU,GACVuB,EAAW0E,EAAqBjG,QAAQkG,MACxC1B,EAAgByB,EAAqBjG,QAAQmG,eAC7CC,EAA+Bb,EAA2BhE,GAyBhE,YAxBqD,IAAlBiD,EAjBC,SAAC7E,EAAO6E,GAG5C,OAFuBhE,EAAoBb,EAAO6E,GAE5Bb,KAAI,SAAC0C,GACzB,MAAO,CACL1G,MAAO0G,EAAa1G,MAAMgE,IAAIwB,GAC9BjF,KAAMmG,EAAa1G,MAAMgE,KAAI,SAACgB,GAAD,OAAOG,EAA0BH,GAAGW,WACjEvF,QAASsG,EAAatG,YAaxBuG,CAA8BF,EAA8B5B,GA5CjC,SAAA7E,GAAU,IACjCK,EAAU,GACZC,EAAY,CACdN,MAAO,GACPO,KAAM,IAiBR,OAfAP,EAAMQ,SAAQ,SAACC,GAAU,IACjBkF,EAAUR,EAA0B1E,GAAMkF,QAC1CiB,EAAiBpB,EAAc/E,GACjC,QAAQuB,KAAK2D,IACfrF,EAAUN,MAAMU,KAAKkG,GACrBtG,EAAUC,KAAKG,KAAKiF,GACpBtF,EAAQK,KAAKJ,GAEbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,MAE/BD,EAAUN,MAAMU,KAAKkG,GACrBtG,EAAUC,KAAKG,KAAKiF,OAIjBtF,EAwBL6B,CACEuE,IAGcjG,SAAQ,SAACF,EAAWvC,GACpC,IAAMqE,EAA+B,CACnC7B,KAAMD,EAAUC,KAAK0B,KAAK,KAC1BI,KAAM,YACNC,KAAM,CACJlC,QAASE,EAAUF,QAAV,kBAAgCE,EAAUF,SAA1C,cAA+DrC,GACxEiC,MAAOM,EAAUN,MACjBoB,MAAOkC,WAAWhD,EAAUN,MAAM,GAAGoB,QAIvCmB,aAAcC,YAAuBlC,EAAUN,MAAO,SAExDK,EAAQK,KAAK0B,MAGR/B,GCnDMwG,EA5FI,SAAAC,GAAW,IAgDAC,EAAUC,EAnCRC,EACtBC,EAqEFC,GAtEwBF,EAsEgBH,EAAQzG,QAAQ,GAAGA,QArEzD6G,EAAoB,GAC1BD,EAAWzG,SAAQ,SAAA4G,GAEjBF,EAAkBxG,KAAgC0G,EAAOhC,aAAa,GAAGiC,WAdzDrD,KAAI,SAAAsD,GACpB,MAAO,CACL/G,KAAM+G,EAAQ,GACdlG,MAAOkG,EAAQ,GACfhG,IAAKgG,EAAQ,WAmBVJ,GA+DT,OA9BoC,SAACK,GACnC,IAAMC,EAA2B,GAoBjC,OAnBAD,EAA+B/G,SAAQ,SAACiH,GACtC,IAAMrF,EAA+B,CACnC7B,KAAMkH,EAAazD,KAAI,SAACvD,GAAU,OAAOA,EAAKF,QAAQ0B,KAAK,KAC3DI,KAAM,YACNC,KAAM,CAIJlC,QAASqH,EAAa,GAAGrH,QACzBJ,MAAOyH,EACPrG,MAAOqG,EAAa,GAAGrG,OAIzBmB,aAAcC,YAAuBiF,EAAc,SAErDD,EAAyB9G,KAAK0B,MAGzBoF,EArB2B,EAXRT,EAsC8BI,EAtCpBH,EAsCqCF,EAAQzG,QAAQ,GAAGmG,eArCrFO,EAAS/C,KAAI,SAAA0D,GAClB,OAAOA,EAAM1D,KAAI,SAAAvD,GAIf,OAFAA,EAAKL,QAtBuB,SAACK,EAAMkH,GACvC,IAAM3G,EAAa2G,EAAgB1G,MAAK,SAAAC,GAAQ,IACxC0G,EAAW1G,EAAI2G,KACf1G,EAASD,EAAI4G,GAEnB,OAASrH,EAAKW,QAAUwG,GAAcnH,EAAKa,MAAQH,KALM,YAQvD,IAAAH,EAGK,MAXkD,YAc5CA,EAAWZ,SAQP2H,CAA0BtH,EAAMuG,GAExCvG,W,QCWAuH,EAtBiB,SAACC,GAAoC,IAG3DjI,EAAsBiI,EAAtBjI,MAAOkI,EAAeD,EAAfC,WAgBf,OAdKA,EAGiBnI,kBAAiCC,EAAOkI,GA9CjC,SAAClI,GAAW,IACnCK,EAAU,GACZC,EAAY,CAAEN,MAAO,GAAIO,KAAM,IAenC,OAbAP,EAAMQ,SAAQ,SAACC,GACbH,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,KAAKG,KAAKD,EAAKF,MAGrB,QAAQyB,KAAKvB,EAAKF,QACpBD,EAAUC,KAAOD,EAAUC,KAAK0B,KAAK,KACrC5B,EAAQK,KAAKJ,GAEbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,QAI5BF,EA2Be6B,CAAuBlC,IAKXgE,KAAI,SAAC1D,EAAWvC,GAKhD,OAJKuC,EAAUF,UACbE,EAAUF,QAAV,cAA4BrC,IA/BE,SAACuC,GAAe,IAC1CN,EAAyBM,EAAzBN,MAGR,MAAO,CACLO,KAJ+BD,EAAlBC,KAKb8B,KAAM,YACNC,KAAM,CACJlC,QAP6BE,EAAZF,QAQjBJ,MAAOA,EACPoB,MARyB,EAAfpB,EAAM0D,OAAa1D,EAAM,GAAGoB,MAAQ,GAYhDmB,aAAcC,YAAuBxC,EAAO,SAoBrCmI,CAA4B7H,OCzDjC8H,EAAU,SAAAC,GAAI,OAAIA,EAAKhD,QAAO,SAACiD,EAAGC,GAAJ,OAAUD,EAAEE,OAAOC,MAAMC,QAAQH,GAAKH,EAAQG,GAAKA,KAAI,KAuB5EI,EAjBS,SAACC,GAAY,IAC7BrG,EAAeqG,EAAO5E,KAAI,SAAA6E,GAAK,OAAIA,EAAMtG,gBACzCuG,EAAmBV,EAAQ7F,GAE3BwG,EAAY,GAUlB,OARAD,EAAiBtI,SAAQ,SAAC8B,GACxByG,EAAUzG,EAAKhD,KAAO,CACpB+C,KAAM,OACN2G,WAAY,UACZ1G,WAIGyG,GCYHE,EAAuB,SAACC,EAAaC,GAEzC,IAAIC,EAAU9F,WAAW4F,GAMzB,YAJI,IAAAC,IACFC,GAAoB9F,WAAW6F,EAvCf,MA0CXC,GAqBHlH,EAAyB,SAAAmH,GAAc,IACrChJ,EAAU,GACZC,EAAY,CACdN,MAAO,GACPO,KAAM,IAcR,OAXA8I,EAAU7I,SAAQ,SAAC8I,GACjB,IAAM5D,EAhEgC,SAAA2D,GACxC,OAAsC,IAAlCA,EAAUjE,aAAa1B,OAClB2F,EAAU,GAGmBA,EAAUjE,aAAaC,QAAO,SAClEC,EACAC,GAEA,OAAOjC,WAAWgC,EAAKlB,YAAcd,WAAWiC,EAAQnB,YACpDkB,EACAC,KAqDoBgE,CAA2BD,GACnDhJ,EAAUC,KAAKG,KAAqCgF,EAAgB8D,WA/C1D5I,QAiDV8E,EAAgB1F,MAAMQ,SAAQ,SAACC,GAzBb,IAACgF,EAAarB,EA0B9B9D,EAAUN,MAAMU,MA1BC+E,EA0BkBhF,EA1BL2D,EA0BWsB,EAAgBtB,WAxBtD,CACLhD,MAAO6H,EAAqBxD,EAAYzC,UAAUoG,QAAS3D,EAAYzC,UAAUyG,OACjFnI,IAAK2H,EAAqBxD,EAAYxC,QAAQmG,QAAS3D,EAAYxC,QAAQwG,OAC3ElJ,KAAMkF,EAAYhF,KAClB2D,WAAYA,QAsBZ/D,EAAQK,KAAKJ,GACbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,OAG1BF,GA6BMqJ,EA1BO,SAAAC,GAAe,IAC7BtJ,EAAU,GAsBhB,OAlB0B6B,EAAuByH,EAAWtJ,SAE1CG,SAAQ,SAACF,EAAWvC,GACpC,IAAMqE,EAA+B,CACnC7B,KAAMD,EAAUC,KAAK0B,KAAK,KAC1BI,KAAM,YACNC,KAAM,CACJlC,QAASE,EAAUF,QAAV,kBAAgCE,EAAUF,SAA1C,cAA+DrC,GACxEiC,MAAOM,EAAUN,MACjBoB,MAAOkC,WAAWhD,EAAUN,MAAM,GAAGoB,QAIvCmB,aAAcC,YAAuBlC,EAAUN,MAAO,SAExDK,EAAQK,KAAK0B,MAGR/B,GC1DMuJ,UA1CQ,SAACC,EAAgBC,GACtC,IAAIlB,EACJ,OAAQkB,GACR,IAAK,WAGH,MAAO,CAAElB,OAFTA,EAASlH,EAAgBmI,GAERd,UAAWJ,EAAgBC,IAC9C,IAAK,YAGH,MAAO,CAAEA,OAFTA,EAASnG,EAAiBoH,GAETd,UAAWJ,EAAgBC,IAC9C,IAAK,eAGH,MAAO,CAAEA,OAFTA,EAASrF,EAAoBsG,GAEZd,UAAWJ,EAAgBC,IAC9C,IAAK,MAGH,MAAO,CAAEA,OAFTA,EAAS/B,EAAWgD,GAEHd,UAAWJ,EAAgBC,IAC9C,IAAK,UACH,OAAOiB,EAET,IAAK,mBAGH,MAAO,CAAEjB,OAFTA,EAASvC,EAAwBwD,GAEhBd,UAAWJ,EAAgBC,IAC9C,IAAK,mBAGH,MAAO,CAAEA,OAFTA,EAASZ,EAAwB6B,GAEhBd,UAAWJ,EAAgBC,IAE9C,IAAK,aAGH,MAAO,CAAEA,OAFTA,EAASc,EAAcG,GAENd,UAAWJ,EAAgBC,IAE9C,QAEEmB,QAAQC,MAAM,wC,gCCpDlB,OA4IejK,UA9Df,SAA0CC,EAAOC,GAG/C,OAGF,SAAuCD,EAAOC,GAAW,IACjDI,EAAU,GACZ4J,EAAiB,MACjBC,EAAsB,EACtBC,EAAuB,EACvB7J,EAAY,CAAEN,MAAO,GAAIO,KAAM,GAAIH,QAAS,IAwBhD,OAvBAJ,EAAMQ,SAAQ,SAACC,IACbwJ,EAsCJ,SAA4BxJ,EAAMR,GAQhC,OANmBA,EAASgB,MAAK,SAACC,GAChC,GAAKT,EAAKW,OAASF,EAAIE,OAAWX,EAAKa,KAAOJ,EAAII,IAChD,OAAOJ,KA1CQM,CAAmBf,EAAMR,OAGxCiK,EAAsBjK,EAASmK,QAAQH,MACXE,GAC1B7J,EAAUN,MAAMU,KAAKD,GACrBH,EAAUC,MAAQE,EAAKF,KAAO,IAC9BD,EAAUF,QAAU6J,EAAe7J,UAGnC+J,EAAuBD,EACvB5J,EAAUC,KAAKK,OACfP,EAAQK,KAAKJ,IACbA,EAAY,CAAEN,MAAO,GAAIO,KAAM,GAAIH,QAAS,KAClCJ,MAAMU,KAAKD,GACrBH,EAAUC,MAAQE,EAAKF,KAAO,IAC9BD,EAAUF,QAAU6J,EAAe7J,aAIzCC,EAAQK,KAAKJ,GAEND,EAlCQgK,CAA6BrK,EAAOC,K,+BC5CtCuC,IAvBgB,SAACxC,EAAOsK,GACrC,IAAIC,EAAW,EAEf,OAAOvK,EAAMgE,KAAI,SAACvD,GAChB,IAAM2G,EAAS,CACbhG,MAAOX,EAAKW,MACZE,IAAKb,EAAKa,IACV8C,WAAY3D,EAAK2D,WACjB7D,KAAME,EAAK6J,GACXE,OAAQD,EACR7G,OAAQjD,EAAK6J,GAAmB5G,OAChC+G,WAAYhK,EAAKiK,UACjBpL,IAAKqL,KAAKC,SACPjH,SAAS,IACTkH,UAAU,IAKf,OAFAN,EAAWA,EAAW9J,EAAK6J,GAAmB5G,OAAS,EAEhD0D","file":"sttJsonAdapter.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 36);\n","/**\nedge cases\n- more segments then words - not an issue if you start by matching words with segment\nand handle edge case where it doesn't find a match\n- more words then segments - orphan words\n */\nfunction groupWordsInParagraphsBySpeakers(words, segments) {\n  // add speakers to each word\n  const wordsWithSpeakers = addSpeakerToEachWord(words, segments.segments);\n  // group words by speakers sequentially\n  const result = groupWordsBySpeaker(wordsWithSpeakers);\n\n  return result;\n};\n\n/**\n* Add speakers to each words\n* if it doesn't have add unknown attribute `U_UKN`\n* @param {*} words\n* @param {*} segments\n*/\nfunction addSpeakerToEachWord(words, segments) {\n  const tmpWordsWithSpeakers = [];\n  words.forEach((word) => {\n    const tmpSpeakerSegment = findSegmentForWord(word, segments);\n\n    word.speaker = formatSpeakerName(tmpSpeakerSegment.speaker);\n    tmpWordsWithSpeakers.push(word);\n  });\n\n  return tmpWordsWithSpeakers;\n}\n\n/**\n * Groups Words by speaker attribute\n * @param {array} wordsWithSpeakers - same as kaldi words list but with a `speaker` label attribute on each word\n * @return {array} - list of paragraph objcts, with words, text and sepaker attributes.\n * where words is an array and the other two are strings.\n */\nfunction groupWordsBySpeaker(wordsWithSpeakers) {\n  let currentSpeaker = wordsWithSpeakers[0].speaker;\n  const results = [ ];\n  let paragraph = { words: [], text: '', speaker: '' };\n  wordsWithSpeakers.forEach((word) => {\n    // if current speaker same as word speaker add words to paragraph\n    if (currentSpeaker === word.speaker) {\n      paragraph.words.push(word);\n      paragraph.text += word.punct + ' ';\n      paragraph.speaker = currentSpeaker;\n    }\n    // if it's not same speaker\n    else {\n      // update current speaker\n      currentSpeaker = word.speaker;\n      // remove spacing in text\n      paragraph.text = paragraph.text.trim();\n      //save  previous paragraph\n      results.push(paragraph);\n      // reset paragraph\n      paragraph = { words: [], text: '', speaker: 'U_UKN' };\n      // add words attributes to new\n      paragraph.words.push(word);\n      paragraph.text += word.punct + ' ';\n    }\n  });\n  // add last paragraph\n  results.push(paragraph);\n\n  return results;\n}\n\n/**\n* Helper functions\n*/\n\n/**\n* given word start and end time attributes\n* looks for segment range that contains that word\n* if it doesn't find any it returns a segment with `UKN`\n* speaker attributes.\n* @param {object} word - word object\n* @param {array} segments - list of segments objects\n* @return {object} - a single segment whose range contains the word\n*/\nfunction findSegmentForWord(word, segments) {\n\n  const tmpSegment = segments.find((seg) => {\n    const segEnd = seg.start + seg.duration;\n\n    return ((word.start >= seg.start) && (word.end <= segEnd));\n  });\n  // if find doesn't find any matches it returns an undefined\n  if (tmpSegment === undefined) {\n    // covering edge case orphan word not belonging to any segments\n    // adding UKN speaker label\n    return {\n      '@type': 'Segment',\n      // keeping both speaker id and gender as this is used later\n      // to format speaker label combining the two\n      speaker: { '@id': 'UKN', gender: 'U' }\n    };\n  } else {\n    // find returns the first element that matches the criteria\n    return tmpSegment;\n  }\n}\n\n/**\n* formats kaldi speaker object into a string\n* Combining Gender and speaker Id\n* @param {object} speaker - BBC kaldi speaker object\n* @return {string} -\n*/\nfunction formatSpeakerName(speaker) {\n  return speaker.gender + '_' + speaker['@id'];\n}\n\nexport default groupWordsInParagraphsBySpeakers;","/**\n * Convert BBC Kaldi json to draftJs\n * see `sample` folder for example of input and output as well as `example-usage.js`\n *\n */\n\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\nimport groupWordsInParagraphsBySpeakers from './group-words-by-speakers.js';\n/**\n * groups words list from kaldi transcript based on punctuation.\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\n * @param {array} words - array of words opbjects from kaldi transcript\n */\n\nconst groupWordsInParagraphs = words => {\n  const results = [];\n  let paragraph = { words: [], text: [] };\n\n  words.forEach(word => {\n    // if word contains punctuation\n    if (/[.?!]/.test(word.punct)) {\n      paragraph.words.push(word);\n      paragraph.text.push(word.punct);\n      paragraph.text = paragraph.text.join(' ');\n      results.push(paragraph);\n      // reset paragraph\n      paragraph = { words: [], text: [] };\n    } else {\n      paragraph.words.push(word);\n      paragraph.text.push(word.punct);\n    }\n  });\n\n  return results;\n};\n\nconst bbcKaldiToDraft = bbcKaldiJson => {\n  const results = [];\n  let tmpWords;\n  let speakerSegmentation = null;\n  let wordsByParagraphs = [];\n\n  // BBC Octo Labs API Response wraps Kaldi response around retval,\n  // while kaldi contains word attribute at root\n  if (bbcKaldiJson.retval !== undefined) {\n    tmpWords = bbcKaldiJson.retval.words;\n    if (bbcKaldiJson.retval.segmentation !== undefined) {\n      speakerSegmentation = bbcKaldiJson.retval.segmentation;\n    }\n  } else {\n    tmpWords = bbcKaldiJson.words;\n    if (bbcKaldiJson.segmentation !== undefined) {\n      speakerSegmentation = bbcKaldiJson.segmentation;\n    }\n  }\n\n  if (speakerSegmentation === null) {\n    wordsByParagraphs = groupWordsInParagraphs(tmpWords);\n  } else {\n    wordsByParagraphs = groupWordsInParagraphsBySpeakers(tmpWords, speakerSegmentation);\n  }\n\n  wordsByParagraphs.forEach((paragraph, i) => {\n    // if paragraph contain words\n    // eg sometimes the speaker segmentation might not contain words :man-shrugging:\n    if (paragraph.words[0] !== undefined) {\n      let speakerLabel = `TBC ${ i }`;\n      if (speakerSegmentation !== null) {\n        speakerLabel = paragraph.speaker;\n      }\n\n      const draftJsContentBlockParagraph = {\n        text: paragraph.text,\n        type: 'paragraph',\n        data: {\n          speaker: speakerLabel,\n          words: paragraph.words,\n          start: paragraph.words[0].start\n        },\n        // the entities as ranges are each word in the space-joined text,\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n        entityRanges: generateEntitiesRanges(paragraph.words, 'punct') // wordAttributeName\n      };\n      results.push(draftJsContentBlockParagraph);\n    }\n  });\n\n  return results;\n};\n\nexport default bbcKaldiToDraft;\n","/**\n * Convert autoEdit2 Json to draftJS\n * see `sample` folder for example of input and output as well as `example-usage.js`\n */\n\nimport generateEntitiesRanges from '../generate-entities-ranges/index';\n\n/**\n * groups words list from autoEdit transcript based on punctuation.\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\n * @param {array} words - array of words objects from autoEdit transcript\n */\n\nconst groupWordsInParagraphs = (autoEditText) => {\n  const results = [];\n  let paragraph = { words: [], text: [] };\n\n  autoEditText.forEach((autoEditparagraph) => {\n    autoEditparagraph.paragraph.forEach((autoEditLine) => {\n      autoEditLine.line.forEach((word) => {\n        // adjusting time reference attributes from\n        // `startTime` `endTime` to `start` `end`\n        // for word object\n        const tmpWord = {\n          text: word.text,\n          start: word.startTime,\n          end: word.endTime,\n        };\n        //  if word contains punctuation\n        if (/[.?!]/.test(word.text)) {\n          paragraph.words.push(tmpWord);\n          paragraph.text.push(word.text);\n          results.push(paragraph);\n          // reset paragraph\n          paragraph = { words: [], text: [] };\n        } else {\n          paragraph.words.push(tmpWord);\n          paragraph.text.push(word.text);\n        }\n      });\n    });\n  });\n\n  return results;\n};\n\nconst autoEdit2ToDraft = (autoEdit2Json) => {\n  const results = [];\n  const tmpWords = autoEdit2Json.text;\n  const wordsByParagraphs = groupWordsInParagraphs(tmpWords);\n\n  wordsByParagraphs.forEach((paragraph, i) => {\n    const draftJsContentBlockParagraph = {\n      text: paragraph.text.join(' '),\n      type: 'paragraph',\n      data: {\n        speaker: `TBC ${ i }`,\n        words: paragraph.words,\n        start: paragraph.words[0].start\n      },\n      // the entities as ranges are each word in the space-joined text,\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text'),\n    };\n    // console.log(JSON.stringify(draftJsContentBlockParagraph,null,2))\n    results.push(draftJsContentBlockParagraph);\n  });\n\n  // console.log(JSON.stringify(results,null,2))\n  return results;\n};\n\nexport default autoEdit2ToDraft;\n","/**\n *  Convert Speechmatics Json to DraftJs\n *  see `sample` folder for example of input and output as well as `example-usage.js`\n */\n\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\n\n/**\n * Determines the speaker of a paragraph by comparing the start time of the paragraph with\n * the speaker times.\n * @param {float} start - Starting point of paragraph\n * @param {array} speakers - list of all speakers with start and end time\n */\nconst getSpeaker = (start, speakers) => {\n  for (var speakerIdx in speakers) {\n    const speaker = speakers[speakerIdx];\n    const segmentStart = parseFloat(start);\n    if (segmentStart >= speaker.start & segmentStart < speaker.end) {\n      return speaker.name;\n    }\n  }\n\n  return 'UNK';\n};\n\n/**\n * groups words list from speechmatics based on speaker change and paragraph length.\n * @param {array} words - array of words objects from speechmatics transcript\n * @param {array} speakers - array of speaker objects from speechmatics transcript\n * @param {int} words - number of words which trigger a paragraph break\n */\nconst groupWordsInParagraphs = (words, speakers, maxParagraphWords) => {\n  const results = [];\n  let paragraph = { words: [], text: [], speaker: '' };\n  let oldSpeaker = getSpeaker(words[0].start, speakers);\n  let newSpeaker;\n  let sentenceEnd = false;\n\n  words.forEach((word) => {\n    newSpeaker = getSpeaker(word.start, speakers);\n    // if speaker changes\n    if (newSpeaker !== oldSpeaker || (paragraph.words.length > maxParagraphWords && sentenceEnd)) {\n      paragraph.speaker = oldSpeaker;\n      results.push(paragraph);\n      oldSpeaker = newSpeaker;\n      // reset paragraph\n      paragraph = { words: [], text: [] };\n    }\n    paragraph.words.push(word);\n    paragraph.text.push(word.punct);\n    sentenceEnd = /[.?!]/.test(word.punct) ? true : false;\n  });\n\n  paragraph.speaker = oldSpeaker;\n  results.push(paragraph);\n\n  return results;\n};\n\n/**\n * Speechmatics treats punctuation as own words. This function merges punctuations with\n * the pevious word and adjusts the total duration of the word.\n * @param {array} words - array of words objects from speechmatics transcript\n */\nconst curatePunctuation = (words) => {\n  const curatedWords = [];\n  words.forEach((word) => {\n    if (/[.?!]/.test(word.name)) {\n      curatedWords[curatedWords.length - 1].name = curatedWords[curatedWords.length - 1].name + word.name;\n      curatedWords[curatedWords.length - 1].duration = (parseFloat(curatedWords[curatedWords.length - 1].duration) + parseFloat(word.duration)).toString();\n    } else {\n      curatedWords.push(word);\n    }\n  }\n  );\n\n  return curatedWords;\n};\n\nconst speechmaticsToDraft = (speechmaticsJson) => {\n  const results = [];\n\n  let tmpWords;\n  tmpWords = curatePunctuation(speechmaticsJson.words);\n  tmpWords = tmpWords.map((element, index) => {\n    return ({\n      start: element.time,\n      end: (parseFloat(element.time) + parseFloat(element.duration)).toString(),\n      confidence: element.confidence,\n      word: element.name.toLowerCase().replace(/[.?!]/g, ''),\n      punct: element.name,\n      index: index,\n    });\n  });\n\n  let tmpSpeakers;\n  tmpSpeakers = speechmaticsJson.speakers;\n  tmpSpeakers = tmpSpeakers.map((element) => {\n    return ({\n      start: parseFloat(element.time),\n      end: (parseFloat(element.time) + parseFloat(element.duration)),\n      name: element.name,\n    });\n  });\n\n  const wordsByParagraphs = groupWordsInParagraphs(tmpWords, tmpSpeakers, 150);\n\n  wordsByParagraphs.forEach((paragraph) => {\n    const paragraphStart = paragraph.words[0].start;\n    const draftJsContentBlockParagraph = {\n      text: paragraph.text.join(' '),\n      type: 'paragraph',\n      data: {\n        speaker: paragraph.speaker,\n        words: paragraph.words,\n        start: paragraphStart\n      },\n      // the entities as ranges are each word in the space-joined text,\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n      entityRanges: generateEntitiesRanges(paragraph.words, 'punct'), // wordAttributeName\n    };\n    results.push(draftJsContentBlockParagraph);\n  });\n\n  return results;\n};\n\nexport default speechmaticsToDraft;\n","export const groupWordsBySpeakerLabel = (words) => {\n  const groupedWords = [];\n  let currentSpeaker = '';\n  words.forEach((word) => {\n    if (word.speaker_label === currentSpeaker) {\n      groupedWords[groupedWords.length - 1].words.push(word);\n    } else {\n      currentSpeaker = word.speaker_label;\n      // start new speaker block\n      groupedWords.push({\n        speaker: word.speaker_label,\n        words: [ word ] });\n    }\n  });\n\n  return groupedWords;\n};\n\nexport const findSpeakerForWord = (word, segments) => {\n  const startTime = parseFloat(word.start_time);\n  const endTime = parseFloat(word.end_time);\n  const firstMatchingSegment = segments.find((seg) => {\n    return startTime >= parseFloat(seg.start_time) && endTime <= parseFloat(seg.end_time);\n  });\n  if (firstMatchingSegment === undefined) {\n    return 'UKN';\n  } else {\n    return firstMatchingSegment.speaker_label.replace('spk_', '');\n  }\n};\n\nconst addSpeakerLabelToWords = (words, segments) => {\n  return words.map(w => Object.assign(w, { 'speaker_label': findSpeakerForWord(w, segments) }));\n};\n\nexport const groupWordsBySpeaker = (words, speakerLabels) => {\n  const wordsWithSpeakers = addSpeakerLabelToWords(words, speakerLabels.segments);\n\n  return groupWordsBySpeakerLabel(wordsWithSpeakers);\n};","/**\n * Converts AWS Transcribe Json to DraftJs\n * see `sample` folder for example of input and output as well as `example-usage.js`\n */\n\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\nimport { groupWordsBySpeaker } from './group-words-by-speakers';\n\nexport const stripLeadingSpace = word => {\n  return word.replace(/^\\s/, '');\n};\n\n/**\n *  @param {json} words  - List of words\n *  @param {string} wordAttributeName - eg 'punct' or 'text' or etc.\n * attribute for the word object containing the text. eg word ={ punct:'helo', ... }\n *  or eg word ={ text:'helo', ... }\n */\nexport const getBestAlternativeForWord = word => {\n  if (/punctuation/.test(word.type)) {\n    return Object.assign(word.alternatives[0], { confidence: 1 }); //Transcribe doesn't provide a confidence for punctuation\n  }\n  const wordWithHighestConfidence = word.alternatives.reduce(function(\n    prev,\n    current\n  ) {\n    return parseFloat(prev.confidence) > parseFloat(current.confidence)\n      ? prev\n      : current;\n  });\n\n  return wordWithHighestConfidence;\n};\n\n/**\n * Normalizes words so they can be used in\n * the generic generateEntitiesRanges() method\n **/\nconst normalizeWord = currentWord => {\n  const bestAlternative = getBestAlternativeForWord(currentWord);\n\n  return {\n    start: parseFloat(currentWord.start_time),\n    end: parseFloat(currentWord.end_time),\n    text: bestAlternative.content,\n    confidence: parseFloat(bestAlternative.confidence)\n  };\n};\n\nexport const appendPunctuationToPreviousWord = (punctuation, previousWord) => {\n  const punctuationContent = punctuation.alternatives[0].content;\n\n  return {\n    ...previousWord,\n    alternatives: previousWord.alternatives.map(w => ({\n      ...w,\n      content: w.content + stripLeadingSpace(punctuationContent)\n    }))\n  };\n};\n\nexport const mapPunctuationItemsToWords = words => {\n  const itemsToRemove = [];\n  const dirtyArray = words.map((word, index) => {\n    let previousWord = {};\n    if (word.type === 'punctuation') {\n      itemsToRemove.push(index - 1);\n      previousWord = words[index - 1];\n\n      return appendPunctuationToPreviousWord(word, previousWord);\n    } else {\n      return word;\n    }\n  });\n\n  return dirtyArray.filter((item, index) => {\n    return !itemsToRemove.includes(index);\n  });\n};\n\n/**\n * groups words list from amazon transcribe transcript based on punctuation.\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\n * @param {array} words - array of words objects from kaldi transcript\n */\nconst groupWordsInParagraphs = words => {\n  const results = [];\n  let paragraph = {\n    words: [],\n    text: []\n  };\n  words.forEach((word) => {\n    const content = getBestAlternativeForWord(word).content;\n    const normalizedWord = normalizeWord(word);\n    if (/[.?!]/.test(content)) {\n      paragraph.words.push(normalizedWord);\n      paragraph.text.push(content);\n      results.push(paragraph);\n      // reset paragraph\n      paragraph = { words: [], text: [] };\n    } else {\n      paragraph.words.push(normalizedWord);\n      paragraph.text.push(content);\n    }\n  });\n\n  return results;\n};\n\nconst groupSpeakerWordsInParagraphs = (words, speakerLabels) => {\n  const wordsBySpeaker = groupWordsBySpeaker(words, speakerLabels);\n\n  return wordsBySpeaker.map((speakerGroup) => {\n    return {\n      words: speakerGroup.words.map(normalizeWord),\n      text: speakerGroup.words.map((w) => getBestAlternativeForWord(w).content),\n      speaker: speakerGroup.speaker\n    };\n  });\n};\n\nconst amazonTranscribeToDraft = amazonTranscribeJson => {\n  const results = [];\n  const tmpWords = amazonTranscribeJson.results.items;\n  const speakerLabels = amazonTranscribeJson.results.speaker_labels;\n  const wordsWithRemappedPunctuation = mapPunctuationItemsToWords(tmpWords);\n  const speakerSegmentation = typeof(speakerLabels) != 'undefined';\n\n  const wordsByParagraphs = speakerSegmentation ?\n    groupSpeakerWordsInParagraphs(wordsWithRemappedPunctuation, speakerLabels) :\n    groupWordsInParagraphs(\n      wordsWithRemappedPunctuation\n    );\n\n  wordsByParagraphs.forEach((paragraph, i) => {\n    const draftJsContentBlockParagraph = {\n      text: paragraph.text.join(' '),\n      type: 'paragraph',\n      data: {\n        speaker: paragraph.speaker ? `Speaker ${ paragraph.speaker }` : `TBC ${ i }`,\n        words: paragraph.words,\n        start: parseFloat(paragraph.words[0].start)\n      },\n      // the entities as ranges are each word in the space-joined text,\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text') // wordAttributeName\n    };\n    results.push(draftJsContentBlockParagraph);\n  });\n\n  return results;\n};\n\nexport default amazonTranscribeToDraft;\n","/**\n * Convert IBM json to draftJS\n * see `sample` folder for example of input and output as well as `example-usage.js`\n *\n */\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\n\nconst ibmToDraft = ibmJson => {\n  // helper function to normalise IBM words at line level\n  const normalizeTimeStampsToWords = timestamps => {\n    return timestamps.map(ibmWord => {\n      return {\n        text: ibmWord[0],\n        start: ibmWord[1],\n        end: ibmWord[2]\n      };\n    });\n  };\n\n  //\n  const normalizeIBMWordsList = ibmResults => {\n    const normalisedResults = [];\n    ibmResults.forEach(result => {\n      // nested array to keep paragraph segmentation same as IBM lines\n      normalisedResults.push(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\n      // TODO: can be revisited - as separate PR by flattening the array like this\n      // normalisedResults = normalisedResults.concact(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\n      // addSpeakersToWords function would need adjusting as would be dealing with a 1D array instead of 2D\n      // if edge case, like in example file, that there's one speaker recognised through all of speaker segemtnation info\n      // could break into paragraph when is over a minute? at end of IBM line?\n      // or punctuation, altho IBM does not seem to provide punctuation?\n    });\n\n    return normalisedResults;\n  };\n\n  // TODO: could be separate file\n  const findSpeakerSegmentForWord = (word, speakerSegments) => {\n    const tmpSegment = speakerSegments.find(seg => {\n      const segStart = seg.from;\n      const segEnd = seg.to;\n\n      return ((word.start === segStart) && (word.end === segEnd));\n    });\n    // if find doesn't find any matches it returns an undefined\n    if (tmpSegment === undefined) {\n      // covering edge case orphan word not belonging to any segments\n      // adding UKN speaker label\n      return 'UKN';\n    } else {\n      // find returns the first element that matches the criteria\n      return `S_${ tmpSegment.speaker }`;\n    }\n  };\n  // add speakers to words\n  const addSpeakersToWords = (ibmWords, ibmSpeakers) => {\n    return ibmWords.map(lines => {\n      return lines.map(word => {\n\n        word.speaker = findSpeakerSegmentForWord(word, ibmSpeakers);\n\n        return word;\n      });\n    });\n  };\n\n  const ibmNormalisedWordsToDraftJs = (ibmNormalisedWordsWithSpeakers) => {\n    const draftJsParagraphsResults = [];\n    ibmNormalisedWordsWithSpeakers.forEach((ibmParagraph) => {\n      const draftJsContentBlockParagraph = {\n        text: ibmParagraph.map((word) => {return word.text;}).join(' '),\n        type: 'paragraph',\n        data: {\n          // Assuming each paragraph in IBM line is the same\n          // for context it just seems like the IBM data structure gives you word level speakers,\n          // but also gives you \"lines\" so assuming each word in a line has the same speaker.\n          speaker: ibmParagraph[0].speaker,\n          words: ibmParagraph,\n          start: ibmParagraph[0].start\n        },\n        // the entities as ranges are each word in the space-joined text,\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n        entityRanges: generateEntitiesRanges(ibmParagraph, 'text'), // wordAttributeName\n      };\n      draftJsParagraphsResults.push(draftJsContentBlockParagraph);\n    });\n\n    return draftJsParagraphsResults;\n  };\n\n  const normalisedWords = normalizeIBMWordsList(ibmJson.results[0].results);\n  // TODO: nested array of words, to keep some sort of paragraphs, in case there's only one speaker\n  // can be refactored/optimised later\n  const ibmNormalisedWordsWithSpeakers = addSpeakersToWords(normalisedWords, ibmJson.results[0].speaker_labels);\n  const ibmDratJs = ibmNormalisedWordsToDraftJs(ibmNormalisedWordsWithSpeakers);\n\n  return ibmDratJs;\n};\n\nexport default ibmToDraft;\n","/**\n * Convert Digital Paper Edit transcript json format to DraftJS\n * More details see\n * https://github.com/bbc/digital-paper-edit\n */\nimport generateEntitiesRanges from '../generate-entities-ranges';\nimport groupWordsInParagraphsBySpeakers from './group-words-by-speakers';\n/**\n * groups words list from kaldi transcript based on punctuation.\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\n * @param {array} words - array of words opbjects from kaldi transcript\n */\nconst groupWordsInParagraphs = (words) => {\n  const results = [];\n  let paragraph = { words: [], text: [] };\n\n  words.forEach((word) => {\n    paragraph.words.push(word);\n    paragraph.text.push(word.text);\n\n    // if word contains punctuation\n    if (/[.?!]/.test(word.text)) {\n      paragraph.text = paragraph.text.join(' ');\n      results.push(paragraph);\n      // reset paragraph\n      paragraph = { words: [], text: [] };\n    }\n  });\n\n  return results;\n};\n\nconst generateDraftJsContentBlock = (paragraph) => {\n  const { words, text, speaker } = paragraph;\n  const start = words.length > 0 ? words[0].start : 0;\n\n  return {\n    text: text,\n    type: 'paragraph',\n    data: {\n      speaker: speaker,\n      words: words,\n      start: start,\n    },\n    // the entities as ranges are each word in the space-joined text,\n    // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n    entityRanges: generateEntitiesRanges(words, 'text'), // wordAttributeName\n  };\n};\n\nconst digitalPaperEditToDraft = (digitalPaperEditTranscriptJson) => {\n  let wordsByParagraphs = [];\n\n  const { words, paragraphs } = digitalPaperEditTranscriptJson;\n\n  if (!paragraphs) {\n    wordsByParagraphs = groupWordsInParagraphs(words);\n  } else {\n    wordsByParagraphs = groupWordsInParagraphsBySpeakers(words, paragraphs);\n  }\n\n  const results = wordsByParagraphs.map((paragraph, i) => {\n    if (!paragraph.speaker) {\n      paragraph.speaker = `TBC ${ i }`;\n    }\n\n    return generateDraftJsContentBlock(paragraph);\n  });\n\n  return results;\n};\n\nexport default digitalPaperEditToDraft;\n","/**\n * Helper function to generate draft.js entityMap from draftJS blocks,\n */\n\n/**\n * helper function to flatten a list.\n * converts nested arrays into one dimensional array\n * @param {array} list\n */\nconst flatten = list => list.reduce((a, b) => a.concat(Array.isArray(b) ? flatten(b) : b), []);\n\n/**\n * helper function to create createEntityMap\n * @param {*} blocks - draftJs blocks\n */\nconst createEntityMap = (blocks) => {\n  const entityRanges = blocks.map(block => block.entityRanges);\n  const flatEntityRanges = flatten(entityRanges);\n\n  const entityMap = {};\n\n  flatEntityRanges.forEach((data) => {\n    entityMap[data.key] = {\n      type: 'WORD',\n      mutability: 'MUTABLE',\n      data,\n    };\n  });\n\n  return entityMap;\n};\n\nexport default createEntityMap;","/**\n * Converts GCP Speech to Text Json to DraftJs\n * see `sample` folder for example of input and output as well as `example-usage.js`\n */\n\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\n\nconst NANO_SECOND = 1000000000;\n\n/**\n * attribute for the sentences object containing the text. eg sentences ={ punct:'helo', ... }\n *  or eg sentences ={ text:'hello', ... }\n * @param sentences\n */\nexport const getBestAlternativeSentence = sentences => {\n  if (sentences.alternatives.length === 0) {\n    return sentences[0];\n  }\n\n  const sentenceWithHighestConfidence = sentences.alternatives.reduce(function(\n    prev,\n    current\n  ) {\n    return parseFloat(prev.confidence) > parseFloat(current.confidence)\n      ? prev\n      : current;\n  });\n\n  return sentenceWithHighestConfidence;\n};\n\nexport const trimLeadingAndTailingWhiteSpace = text => {\n  return text.trim();\n};\n\n/**\n * GCP does not provide a nanosecond attribute if the word starts at 0 nanosecond\n * @param startSecond\n * @param nanoSecond\n * @returns {number}\n */\nconst computeTimeInSeconds = (startSecond, nanoSecond) => {\n\n  let seconds = parseFloat(startSecond);\n\n  if (nanoSecond !== undefined) {\n    seconds = seconds + parseFloat(nanoSecond / NANO_SECOND);\n  }\n\n  return seconds;\n};\n\n/**\n * Normalizes words so they can be used in\n * the generic generateEntitiesRanges() method\n **/\nconst normalizeWord = (currentWord, confidence) => {\n\n  return {\n    start: computeTimeInSeconds(currentWord.startTime.seconds, currentWord.startTime.nanos),\n    end: computeTimeInSeconds(currentWord.endTime.seconds, currentWord.endTime.nanos),\n    text: currentWord.word,\n    confidence: confidence\n  };\n};\n\n/**\n * groups words list from GCP Speech to Text response.\n * @param {array} sentences - array of sentence objects from GCP STT\n */\nconst groupWordsInParagraphs = sentences => {\n  const results = [];\n  let paragraph = {\n    words: [],\n    text: []\n  };\n\n  sentences.forEach((sentence) => {\n    const bestAlternative = getBestAlternativeSentence(sentence);\n    paragraph.text.push(trimLeadingAndTailingWhiteSpace(bestAlternative.transcript));\n\n    bestAlternative.words.forEach((word) => {\n      paragraph.words.push(normalizeWord(word, bestAlternative.confidence));\n    });\n    results.push(paragraph);\n    paragraph = { words: [], text: [] };\n  });\n\n  return results;\n};\n\nconst gcpSttToDraft = gcpSttJson => {\n  const results = [];\n  // const speakerLabels = gcpSttJson.results[0]['alternatives'][0]['words'][0]['speakerTag']\n  // let speakerSegmentation = typeof(speakerLabels) != 'undefined';\n\n  const wordsByParagraphs = groupWordsInParagraphs(gcpSttJson.results);\n\n  wordsByParagraphs.forEach((paragraph, i) => {\n    const draftJsContentBlockParagraph = {\n      text: paragraph.text.join(' '),\n      type: 'paragraph',\n      data: {\n        speaker: paragraph.speaker ? `Speaker ${ paragraph.speaker }` : `TBC ${ i }`,\n        words: paragraph.words,\n        start: parseFloat(paragraph.words[0].start)\n      },\n      // the entities as ranges are each word in the space-joined text,\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text') // wordAttributeName\n    };\n    results.push(draftJsContentBlockParagraph);\n  });\n\n  return results;\n};\n\nexport default gcpSttToDraft;\n","import bbcKaldiToDraft from './bbc-kaldi/index';\nimport autoEdit2ToDraft from './autoEdit2/index';\nimport speechmaticsToDraft from './speechmatics/index';\nimport amazonTranscribeToDraft from './amazon-transcribe/index';\nimport ibmToDraft from './ibm/index';\nimport digitalPaperEditToDraft from './digital-paper-edit/index';\nimport createEntityMap from './create-entity-map/index';\nimport gcpSttToDraft from './google-stt/index';\n\n/**\n * Adapters for STT conversion\n * @param {json} transcriptData - A json transcript with some word accurate timecode\n * @param {string} sttJsonType - the type of transcript supported by the available adapters\n */\nconst sttJsonAdapter = (transcriptData, sttJsonType) => {\n  let blocks;\n  switch (sttJsonType) {\n  case 'bbckaldi':\n    blocks = bbcKaldiToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n  case 'autoedit2':\n    blocks = autoEdit2ToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n  case 'speechmatics':\n    blocks = speechmaticsToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n  case 'ibm':\n    blocks = ibmToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n  case 'draftjs':\n    return transcriptData; // (typeof transcriptData === 'string')? JSON.parse(transcriptData): transcriptData;\n\n  case 'amazontranscribe':\n    blocks = amazonTranscribeToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n  case 'digitalpaperedit':\n    blocks = digitalPaperEditToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n\n  case 'google-stt':\n    blocks = gcpSttToDraft(transcriptData);\n\n    return { blocks, entityMap: createEntityMap(blocks) };\n\n  default:\n    // code block\n    console.error('Did not recognize the stt engine.');\n  }\n};\n\nexport default sttJsonAdapter;\nexport { createEntityMap };","/**\n edge cases\n- more segments then words - not an issue if you start by matching words with segment\nand handle edge case where it doesn't find a match\n- more words then segments - orphan words?\n*\n* Takes in list of words and list of paragraphs (paragraphs have speakers info associated with it)\n```js\n{\n  \"words\": [\n    {\n      \"id\": 0,\n      \"start\": 13.02,\n      \"end\": 13.17,\n      \"text\": \"There\"\n    },\n    {\n      \"id\": 1,\n      \"start\": 13.17,\n      \"end\": 13.38,\n      \"text\": \"is\"\n    },\n    ...\n    ],\n  \"paragraphs\": [\n    {\n      \"id\": 0,\n      \"start\": 13.02,\n      \"end\": 13.86,\n      \"speaker\": \"TBC 00\"\n    },\n    {\n      \"id\": 1,\n      \"start\": 13.86,\n      \"end\": 19.58,\n      \"speaker\": \"TBC 1\"\n    },\n    ...\n  ]\n}\n```\n*  and returns a list of words grouped into paragraphs, with words, text and speaker attribute\n```js\n[\n  {\n    \"words\": [\n      {\n        \"id\": 0,\n        \"start\": 13.02,\n        \"end\": 13.17,\n        \"text\": \"There\"\n      },\n      {\n        \"id\": 1,\n        \"start\": 13.17,\n        \"end\": 13.38,\n        \"text\": \"is\"\n      },\n      {\n        \"id\": 2,\n        \"start\": 13.38,\n        \"end\": 13.44,\n        \"text\": \"a\"\n      },\n      {\n        \"id\": 3,\n        \"start\": 13.44,\n        \"end\": 13.86,\n        \"text\": \"day.\"\n      }\n    ],\n    \"text\": \"There is a day.\",\n    \"speaker\": \"TBC 00\"\n  },\n  ...\n]\n```\n */\nfunction groupWordsInParagraphsBySpeakers(words, segments) {\n  const result = addWordsToSpeakersParagraphs(words, segments);\n\n  return result;\n};\n\nfunction addWordsToSpeakersParagraphs (words, segments) {\n  const results = [];\n  let currentSegment = 'UKN';\n  let currentSegmentIndex = 0;\n  let previousSegmentIndex = 0;\n  let paragraph = { words: [], text: '', speaker: '' };\n  words.forEach((word) => {\n    currentSegment = findSegmentForWord(word, segments);\n    // if a segment exists for the word\n    if (currentSegment) {\n      currentSegmentIndex = segments.indexOf(currentSegment);\n      if (currentSegmentIndex === previousSegmentIndex) {\n        paragraph.words.push(word);\n        paragraph.text += word.text + ' ';\n        paragraph.speaker = currentSegment.speaker;\n      }\n      else {\n        previousSegmentIndex = currentSegmentIndex;\n        paragraph.text.trim();\n        results.push(paragraph);\n        paragraph = { words: [], text: '', speaker: '' };\n        paragraph.words.push(word);\n        paragraph.text += word.text + ' ';\n        paragraph.speaker = currentSegment.speaker;\n      }\n    }\n  });\n  results.push(paragraph);\n\n  return results;\n}\n\n/**\n* Helper functions\n*/\n\n/**\n* given word start and end time attributes\n* looks for segment range that contains that word\n* if it doesn't find any it returns a segment with `UKN`\n* speaker attributes.\n* @param {object} word - word object\n* @param {array} segments - list of segments objects\n* @return {object} - a single segment whose range contains the word\n*/\nfunction findSegmentForWord(word, segments) {\n\n  const tmpSegment = segments.find((seg) => {\n    if ((word.start >= seg.start) && (word.end <= seg.end)) {\n      return seg;\n    }\n  });\n\n  return tmpSegment;\n}\n\nexport default groupWordsInParagraphsBySpeakers;","/**\n * Helper function to generate draft.js entities,\n * see unit test for example data structure\n * it adds offset and length to recognise word in draftjs\n */\n\n/**\n *  @param {json} words  - List of words\n *  @param {string} wordAttributeName - eg 'punct' or 'text' or etc.\n * attribute for the word object containing the text. eg word ={ punct:'helo', ... }\n *  or eg word ={ text:'helo', ... }\n */\nconst generateEntitiesRanges = (words, wordAttributeName) => {\n  let position = 0;\n\n  return words.map((word) => {\n    const result = {\n      start: word.start,\n      end: word.end,\n      confidence: word.confidence,\n      text: word[wordAttributeName],\n      offset: position,\n      length: word[wordAttributeName].length,\n      risk_level: word.risklevel,\n      key: Math.random()\n        .toString(36)\n        .substring(6),\n    };\n    // increase position counter - to determine word offset in paragraph\n    position = position + word[wordAttributeName].length + 1;\n\n    return result;\n  });\n};\n\nexport default generateEntitiesRanges;\n"],"sourceRoot":""}